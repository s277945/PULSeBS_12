Sprint 1 retrospective (team 12)
=====================================

- [process measures](#process-measures)
- [quality measures](#quality-measures)
- [general assessment](#assessment)

## PROCESS MEASURES 

### Macro statistics

- Number of stories committed vs done  
    - 5 stories committed
    - 5 stories done
- Total points committed vs done
    - 23 points committed
    - 23 points done
- Nr of hours planned vs spent (as a team)
    - 77 hours planned
    - 74.55 hours done


### Detailed statistics

| Story  | # Tasks | Points | Hours est. | Hours actual |
|--------|---------|--------|------------|--------------|
| _#1_       |    6     |   5     |      6h 45m      |       7h 55m       |
| _#2_      |     7    |    5    |     6h 55m    |       7h        |
| _#3_      |     4    |    8    |     1h 20m       |        5h       |
| _#4_      |     1    |    3    |      1h 30m      |       1h 30m       |
| _#5_       |    4     |    2    |      1h 50m      |      1h 45m        |


- Hours per task (average, standard deviation):
    - Average: 4.46 hrs per task
    - Standard deviation: 1.5 hrs

- Total task estimation error ratio: sum of total hours estimation / sum of total hours spent from previous table:
    -  77 / 74.55 =  1.03
## QUALITY MEASURES 

- Unit Testing:
  - Total hours estimated: 7h
  - Total hours spent: 10h 10m
  - Nr of automated unit test cases: 16
  - Coverage (overall): 81%
- E2E testing:
  - Total hours estimated: 6h 
  - Total hours spent 5h 10m
- Code review 
  - Total hours estimated: 4h 45m
  - Total hours spent: 6h
- Technical Debt management
  - Total hours estimated: 1h
  - Total hours spent: 20m
  - Hours estimated for remediation by SonarQube: 1h 15m
  - Hours spent on remediation: -
  - debt ratio (as reported by SonarQube under "Measures-Maintainability"): 0%
  - rating for each quality characteristic reported in SonarQube under "Measures"
    - reliability: A
    - security: A
    - maintainability: A

## ASSESSMENT

- What caused your errors in estimation (if any)?
    - In general our estimations were pretty accurate, in fact our task estimation error ratio is just 1.02; the worst estimation was on the first story, because we overestimated by around 4 hrs.

- What lessons did you learn (both positive and negative) in this sprint?
    - We spent more time on tests than in the prevoius project, but still not enough (only 47 % coverage). 
    - We experimented with new technologies to make the project better, as opposed to sticking with what we know. For example with the process of automatically sending out emails.

- Which improvement goals set in the previous retrospective were you able to achieve? 
    - We spent more time in the beginning to carefully design the database, so that we didn't need to modify the db schema during the sprint.
  
- Which ones you were not able to achieve? Why?
     - We feel like we got better at logging our work, but still we weren't precise enough: for example, we didn't separately log time spent on code review.

- Improvement goals for the next sprint and how to achieve them (technical tasks, team coordination, etc.)
     - Better time estimation
     - Distribution of the working hours per week
     - Communication issue in team

- One thing you are proud of as a Team!!
    - We were able to deliver a stable and working product in a short time.
    
# Estimation - Sprint #1

## Story #1

+ \# of tasks committed: **6**
+ \# of tasks completed: **6**
+ \# of members who worked on it: **4**
+ Average time on task per member: **1.3 hour**
+ Distribution of time:
     + Each member worked for **2 hours**, of which
            + decision, learning and setup: 1.5 h/member
            + actual development of project: 0.5 h/member
            + testing: 0.5 h/member
    + In total: 2 hours * 4 members = **8 hours**

## Story #2

+ \# of tasks committed: **7**
+ \# of tasks completed: **7**
+ \# of members who worked on it: **5**
+ Average time on task per member: **85 mins**
+ Distribution of time:
     + Each member worked for **3.5 hours**, of which
            + actual development of project: 3 h/member
            + testing: 0.5 h/member
    + In total: 3.5 hours * 5 members = **17.5 hours**

## Story #3
+ \# of tasks committed: **4**
+ \# of tasks completed: **4**
+ \# of members who worked on it: **3**
+ Average time on task per member: **1.25 hour**
+ Distribution of time:
    + Each member worked for **3.5 hours**, of which
        + actual development of project: 3 h/member
        + testing: 0.5 h/member 
    + In total: 3.5 hours * 3 members = **10.5 hours**

## Story #4
+ \# of tasks committed: **1**
+ \# of tasks completed: **1**
+ \# of members who worked on it: **1**
+ Average time on task per member: **1.5 hours**
+ Distribution of time:
    + Each member worked for **1.5 hours**, of which
        + actual development of project: 1 h/member
        + testing: 0.5 h/member
    + In total: 1.5 hours * 1 members = **1.5 hours**

## Story #5
+ \# of tasks committed: **4**
+ \# of tasks completed: **4**
+ \# of members who worked on it: **3**
+ Average time on task per member: **20 mins**
+ Distribution of time:
    + Each member worked for **30 mins**, of which
        + actual development of project: 1 h/member
        + testing: 0.5 h/member
    + In total: 30 mins * 3 members = **1.5 hours**

## Use cases
+ (no task creation for this)
+ \# of members who worked on it: **2**
+ Time spent: **10 hours**

## Scrum meetings
+ \# of members who worked on it: **7**
+ Each member worked for **0.5 hour **
+ In total: (0.5 hours * 7 members) * 2 weeks = **7 hours**

## Final results

+ Time spent per member for the sprint: **~10 hours**
+ Total time spent for the sprint: **75 hours**
+ Percentage of delay: 5%

## Future improvements for this sprint

+ Better time estimation
+ Distribution of the working hours per week
+ Communication issue in team
